{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951e7ec1-b04a-4974-922c-a8184a5a4102",
   "metadata": {},
   "source": [
    "### Tutorial 4 Pivot tables and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25203b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Creating yearly data by aggregating monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3acca29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7b8f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'complete_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_173/3648279621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sales_volume_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'complete_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'complete_dataset.csv'"
     ]
    }
   ],
   "source": [
    "df_sales_volume_data = pd.read_csv('complete_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_volume_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b6411",
   "metadata": {},
   "source": [
    "#### First, we create a pivot table, where we aggregate the sum of the number of items sold per product and year. When there are no iems sold, we replace with zero instead of missing value.\n",
    "\n",
    "#### Then we set margins to true to create totals for rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(df_sales_volume_data,index=[\"Year\"],values=[\"Number_of_items\"],\n",
    "    columns=[\"Prodno\"],aggfunc='sum',fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba98ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceeb8ff-036c-445c-a250-68abe2f679a3",
   "metadata": {},
   "source": [
    "#### We convert the pivot to dataframe so it is easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot=pd.DataFrame(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e295609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45a335-e947-4aa8-b238-d71f45abe17a",
   "metadata": {},
   "source": [
    "#### We drop the column 'All' that sums up each row and keep the row 'All' since we need it to sort top sold products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.columns=df_pivot.columns.droplevel() \n",
    "df_pivot.drop('All', axis=1,inplace=True) \n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207d92",
   "metadata": {},
   "source": [
    "#### 1) We select the top 10 products and sort them. \n",
    "#### 2) We create a list with the top 10 sold products\n",
    "#### 3) We drop 'All' row since we dont need it anymore to make the selection\n",
    "#### 4) We slice the pivot_df and capture only the 10 top sold products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeccce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list=pd.DataFrame(df_pivot.loc['All'].sort_values(ascending=False).head(10))\n",
    "prod_list=prod_list.index.tolist()\n",
    "df_pivot.drop('All',inplace=True)\n",
    "df_top_prod=df_pivot[prod_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4775e-3d4a-4991-bfa9-c23f372bcd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ff894-ea23-4bc7-97b0-9e62fe394ca1",
   "metadata": {},
   "source": [
    "#### Finally, we plot the yearly demand for the top 10 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37199cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_top_prod).plot(figsize=(15,6))\n",
    "plt.xlabel('Yearly demand top 10 products')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57830ab-5c68-43b6-8707-f4edc5eb8a61",
   "metadata": {},
   "source": [
    "### Tutorial 5 Calculations of EOQ, weighted moving averages, and smoothed moving averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a5093-83fb-4e3d-899e-871c40143202",
   "metadata": {},
   "source": [
    "#### To calculate yearly EOQ, we start with transposing the pivot table, years as columns and products as rows and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8263fa-1f57-46be-8d67-d8bf7e371fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662366f-b983-45da-bfea-07aa0423196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot=pivot.T\n",
    "pivot=pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b503273-acc5-4216-8d46-d24ad355517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6196556-b330-42b8-aca4-58b835d14bba",
   "metadata": {},
   "source": [
    "#### Calculate EOQ by looping over one column at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e3050-d3f4-4783-890e-6092148cc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot.columns.tolist()[1:-1]:\n",
    "    pivot[f'EOQ_{i}']=np.sqrt(pivot[i]*0.05/0.45*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e876fc0-b32f-4706-816c-a97978df658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500ac1c-15c7-49e4-9e33-e3f950e6d134",
   "metadata": {},
   "source": [
    "#### Forecast quantities using 4 year weighted moving averages with weights 0.4, 0.3, 0.2 and 0.1 starting from the most recent year, for the 10 top products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f710bc8-3dd3-46d1-a579-03764b595aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.array([0.1,0.2,0.3,0.4])\n",
    "sum_weights=np.sum(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fbb3c-a86f-4683-a712-cd0b4572b5a8",
   "metadata": {},
   "source": [
    "#### We create a dictionary with elements from the columns list of our top_prod_df and value 0. Add year 2021 to be able to forecast. This dictionary is then added to the original dataframe with the index 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab4143-c215-4326-b096-e5557a710efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict=dict((el,0) for el in df_top_prod.columns.tolist())\n",
    "df1 = pd.DataFrame([my_dict], index=['2021'])\n",
    "df_top_prod=df_top_prod.append(df1)\n",
    "df_top_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f0785-5a82-40b2-9bc7-f7357c7a16d4",
   "metadata": {},
   "source": [
    "#### Loop over the columns to calculate weighted moving averages. \n",
    "#### Create a new column and name it with the formatting method weighted_'x', where x is the original column name. \n",
    "#### Then the value at each specific cell is smoothed over a window of 4 years, by applying specified weights, with higher weights to the recent years and shifting it 1 cell below so that we get the forecast of the next year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b3af7-2dac-4a37-b716-738e7ac57b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_top_prod.columns.tolist()[:10]:\n",
    "    df_top_prod[f'weighted_{i}']=(df_top_prod[i]).rolling(window=4).apply(lambda x: np.sum(weights*x)/sum_weights,raw=False).shift(1)\n",
    "df_top_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d295ab8-9c5c-40a1-ad2c-305c092ac2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### To forecast  quantities exponential moving average, similarly to WMA, we once again loop over the columns list.\n",
    "#### Differently from WMA, EWM, is a built in function in Python, where alfa is calculated as 2/span+1 (look up documentation for more information). \n",
    "#### We use adjust False so that it starts on the row we indicate, in this case index 3 and ignores previous rows(0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339bc4e-4d4e-45d5-8dad-5307134f97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_top_prod.columns.tolist():\n",
    "    df_top_prod[f'ema_{i}']=df_top_prod[i][3:].ewm(span=4,adjust=False).mean().shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47c8db-9d88-4bd0-9075-2b0e0261368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db282e-55ea-485a-aba9-a6a7efb8c953",
   "metadata": {},
   "source": [
    "#### Export the data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f554fa-c009-4ff8-b2c0-394b1f9f7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_prod.to_excel(\"df_top_prod.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
