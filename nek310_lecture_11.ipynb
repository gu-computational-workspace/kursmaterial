{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92760,"databundleVersionId":11058817,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:52:46.276771Z","iopub.execute_input":"2025-02-10T16:52:46.277199Z","iopub.status.idle":"2025-02-10T16:52:46.287981Z","shell.execute_reply.started":"2025-02-10T16:52:46.277172Z","shell.execute_reply":"2025-02-10T16:52:46.286676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default=pd.read_csv('/kaggle/input/nek-310-lecture-11/defcc (1).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:52:50.273977Z","iopub.execute_input":"2025-02-10T16:52:50.274406Z","iopub.status.idle":"2025-02-10T16:52:50.37314Z","shell.execute_reply.started":"2025-02-10T16:52:50.27435Z","shell.execute_reply":"2025-02-10T16:52:50.37156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:52:53.588808Z","iopub.execute_input":"2025-02-10T16:52:53.589332Z","iopub.status.idle":"2025-02-10T16:52:53.625109Z","shell.execute_reply.started":"2025-02-10T16:52:53.589295Z","shell.execute_reply":"2025-02-10T16:52:53.623821Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Today we will look into some more modern models, like Random Forests and XG Boost</h2>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:52:58.225476Z","iopub.execute_input":"2025-02-10T16:52:58.225902Z","iopub.status.idle":"2025-02-10T16:52:58.231746Z","shell.execute_reply.started":"2025-02-10T16:52:58.22587Z","shell.execute_reply":"2025-02-10T16:52:58.230407Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>First we just try to fit the models on the raw data and later we will make some more data explorations to see if we can improve model performance.</h2>","metadata":{}},{"cell_type":"code","source":"X_def = default.drop(['dpnm','ID'],axis=1) \nY_def=default['dpnm']\n\nX_std = StandardScaler().fit_transform(X_def)\n\nx_train,x_test,y_train,y_test = train_test_split(X_std,Y_def,test_size=0.3,random_state=42)\n#len(x_test),len(x_train),len(y_train),len(y_test)\ny_train = np.ravel(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:53:00.851359Z","iopub.execute_input":"2025-02-10T16:53:00.851727Z","iopub.status.idle":"2025-02-10T16:53:00.91199Z","shell.execute_reply.started":"2025-02-10T16:53:00.851702Z","shell.execute_reply":"2025-02-10T16:53:00.910972Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Random Forest</h2>","metadata":{}},{"cell_type":"code","source":"# Create the model with 100 trees\nmodelRF = RandomForestClassifier(n_estimators=300, criterion='entropy',\n                                 oob_score=True,\n                                 bootstrap=True,\n                               random_state=2, \n                               max_features ='sqrt' ,\n                               n_jobs=-1, verbose = 0).fit(x_train, y_train)\n\n\n# Fit on training data\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nRF_roc_auc_train = roc_auc_score(y_train, np.argmax(modelRF.oob_decision_function_,axis=1))\nfpr_train_RF, tpr_train_RF, thresholds_train_RF = roc_curve(y_train, modelRF.oob_decision_function_[:,1])\nplt.figure()\nplt.plot(fpr_train_RF, tpr_train_RF, label='Logistic Regression (area = %0.2f)' % RF_roc_auc_train)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic training data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:53:04.466345Z","iopub.execute_input":"2025-02-10T16:53:04.466722Z","iopub.status.idle":"2025-02-10T16:53:15.498707Z","shell.execute_reply.started":"2025-02-10T16:53:04.466698Z","shell.execute_reply":"2025-02-10T16:53:15.497324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, modelRF.predict_proba(x_test)[:,1])\nfpr, tpr, thresholds = roc_curve(y_test, modelRF.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:55:14.274746Z","iopub.execute_input":"2025-02-10T12:55:14.275105Z","iopub.status.idle":"2025-02-10T12:55:15.18061Z","shell.execute_reply.started":"2025-02-10T12:55:14.27508Z","shell.execute_reply":"2025-02-10T12:55:15.17933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_x_test=pd.DataFrame(x_test)\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(modelRF, df_x_test, y_test,\n                            n_repeats=30,\n                            random_state=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:18:15.896074Z","iopub.execute_input":"2025-02-10T12:18:15.896644Z","iopub.status.idle":"2025-02-10T12:20:44.036226Z","shell.execute_reply.started":"2025-02-10T12:18:15.896607Z","shell.execute_reply":"2025-02-10T12:20:44.034933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.concat([pd.DataFrame({'Variable': pd.DataFrame(X_def).columns.tolist()}),pd.DataFrame({'Importance':result.importances_mean})],axis=1)\ndf1=df.sort_values(by='Importance',ascending=False)\ndf1.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:21:33.011212Z","iopub.execute_input":"2025-02-10T12:21:33.011646Z","iopub.status.idle":"2025-02-10T12:21:33.047716Z","shell.execute_reply.started":"2025-02-10T12:21:33.011617Z","shell.execute_reply":"2025-02-10T12:21:33.045855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Let's see if we can impmrove the modelfit by tweaking som model hyperparameters</h2>\n<h3><br><br>\"n estimators\" is the number of trees in the forest.\n<br><br>\"max features\" is the number of features randomly selected for each split of a tree.\n<br><br>\"max depth\" is the max depth of the trees.\n<br><br>\"min samples leaf\" is the number samples required at a leaf node for a new split to happen.\n<br><br>\"min samples split\" is the number of samples to split an internal node.\n<br><br>\"criterion\" is the way the gain is measured.</h3>\n","metadata":{}},{"cell_type":"code","source":"from scipy.stats import randint as sp_randint\n\nrfc = RandomForestClassifier(random_state = 42)\n\nparams = {'n_estimators' : [100],\n              'max_features' : [7,9,12],\n              'max_depth': [2,4,6,8,10,12],\n              'min_samples_leaf':[10,15,20,30]}\n\nrsearch_rfc = RandomizedSearchCV(rfc, param_distributions= params, cv = 5, scoring = 'roc_auc',n_iter = 200,random_state = 42,n_jobs = -1,return_train_score = True)\n\nrsearch_rfc.fit(x_train, y_train)\n    \nprint(\"Tuned RF Parameters: {}\".format(rsearch_rfc.best_params_))\nprint(\"_\" * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:01:59.946828Z","iopub.execute_input":"2025-02-10T16:01:59.947317Z","iopub.status.idle":"2025-02-10T16:23:32.95083Z","shell.execute_reply.started":"2025-02-10T16:01:59.947283Z","shell.execute_reply":"2025-02-10T16:23:32.949176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the model with 100 trees\nmodelRF = RandomForestClassifier(n_estimators=100, \n                                 min_samples_leaf=20,\n                                 max_depth=15,\n                                 oob_score=True,\n                                 bootstrap=True,\n                               random_state=2, \n                               max_features =12 ,\n                               n_jobs=-1, verbose = 0).fit(x_train, y_train)\n\n\n# Fit on training data\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nRF_roc_auc_train = roc_auc_score(y_train, np.argmax(modelRF.oob_decision_function_,axis=1))\nfpr_train_RF, tpr_train_RF, thresholds_train_RF = roc_curve(y_train, modelRF.oob_decision_function_[:,1])\nplt.figure()\nplt.plot(fpr_train_RF, tpr_train_RF, label='Logistic Regression (area = %0.2f)' % RF_roc_auc_train)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic training data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:29:08.671331Z","iopub.execute_input":"2025-02-10T16:29:08.671824Z","iopub.status.idle":"2025-02-10T16:29:14.239129Z","shell.execute_reply.started":"2025-02-10T16:29:08.671789Z","shell.execute_reply":"2025-02-10T16:29:14.237761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, modelRF.predict_proba(x_test)[:,1])\nfpr, tpr, thresholds = roc_curve(y_test, modelRF.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:29:57.949622Z","iopub.execute_input":"2025-02-10T16:29:57.950009Z","iopub.status.idle":"2025-02-10T16:29:58.447722Z","shell.execute_reply.started":"2025-02-10T16:29:57.949978Z","shell.execute_reply":"2025-02-10T16:29:58.446346Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>XG Boost. Is boosting algorithm that has been highly succesful in winning e.g. Kaggle competitions. An overview is given at www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/</h2>","metadata":{}},{"cell_type":"code","source":"#model = xgb.XGBClassifier()\nmodel = xgb.XGBClassifier(n_jobs=-1, objective='binary:logistic', booster='dart', gamma=0\n                       , learning_rate=0.01, n_estimators=300, reg_alpha=1, reg_lambda=0)\nmodel.fit(x_train, y_train)\npredictions_train = model.predict_proba(x_train)\npredictions_test = model.predict_proba(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T15:09:22.31068Z","iopub.execute_input":"2025-02-10T15:09:22.311161Z","iopub.status.idle":"2025-02-10T15:12:42.447174Z","shell.execute_reply.started":"2025-02-10T15:09:22.31113Z","shell.execute_reply":"2025-02-10T15:12:42.446366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XG_roc_auc_train = roc_auc_score(y_train, predictions_train[:,1])\nfpr_train_XG, tpr_train_XG, thresholds_train_XG = roc_curve(y_train, predictions_train[:,1])\nplt.figure()\nplt.plot(fpr_train_XG, tpr_train_XG, label='XG Boost (area = %0.2f)' % XG_roc_auc_train)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic training data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:00:08.951477Z","iopub.execute_input":"2025-02-10T13:00:08.951948Z","iopub.status.idle":"2025-02-10T13:00:09.298673Z","shell.execute_reply.started":"2025-02-10T13:00:08.951918Z","shell.execute_reply":"2025-02-10T13:00:09.297319Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>What about test data?</h2>","metadata":{}},{"cell_type":"code","source":"XG_roc_auc_test = roc_auc_score(y_test, predictions_test[:,1])\nfpr_test_XG, tpr_test_XG, thresholds_test_XG = roc_curve(y_test, predictions_test[:,1])\nplt.figure()\nplt.plot(fpr_test_XG, tpr_test_XG, label='XG Boost (area = %0.2f)' % XG_roc_auc_test)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic test data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:00:19.135515Z","iopub.execute_input":"2025-02-10T13:00:19.135894Z","iopub.status.idle":"2025-02-10T13:00:19.477281Z","shell.execute_reply.started":"2025-02-10T13:00:19.135864Z","shell.execute_reply":"2025-02-10T13:00:19.475928Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Clearly there is an over-fit to the training data. So we try to search trough a grid of (hyper)parameter values for the XG Boost to minimize the problem. There are a lot of parameters that can be tweaked but we focus on a few of them. </h2>\n<h3>\n<br>\"Learning rate\" determines how much each tree contributes to the model. \n<br><br>\"Max depth\" determines how large the trees may get. \n<br><br>\"Min child weight\" is the minimum number of observations in a leaf node. \n<br><br>\"Gamma\" is a global regularisation parameter, it sets a lower limit on the gain (improvement) for adding new nodes. \n<br><br>\"Colsample bytree\" sets the ratio of features randomly selected for each tree.</h3>","metadata":{}},{"cell_type":"code","source":"mod1= xgb.XGBClassifier()\n\nparam_grid = {\"learning_rate\"    : [0.03, 0.04, 0.05] ,\n                  \"max_depth\"        : [5, 6, 7, 8],\n                 \"min_child_weight\" : [11, 12, 13],\n                 \"gamma\"            : [0.3, 0.4, 0.5],\n                 \"colsample_bytree\" : [0.3, 0.4, 0.5, 0.6] }\n  \n#Building a 5 fold CV GridSearchCV object\nmod_RS = RandomizedSearchCV(mod1, param_grid ,cv = 5, scoring = 'roc_auc',n_iter = 200,n_jobs = -1)\n\nmod_RS.fit(x_train, y_train)\n    \nprint(\"Tuned XG Boost Parameters: {}\".format(mod_RS.best_params_))\nprint(\"_\" * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:54:54.357847Z","iopub.execute_input":"2025-02-10T16:54:54.358236Z","iopub.status.idle":"2025-02-10T16:58:02.410393Z","shell.execute_reply.started":"2025-02-10T16:54:54.358207Z","shell.execute_reply":"2025-02-10T16:58:02.406788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model = xgb.XGBClassifier()\nmodel = xgb.XGBClassifier(n_jobs=-1, objective='binary:logistic', booster='dart',\n                          min_child_weight=13, max_depth=6, learning_rate=0.05, gamma=0.4, n_estimators=300, \n                          colsample_bytree=0.6, reg_alpha=1, reg_lambda=0)\nmodel.fit(x_train, y_train)\npredictions_train = model.predict_proba(x_train)\npredictions_test = model.predict_proba(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:10:54.807572Z","iopub.execute_input":"2025-02-10T14:10:54.807906Z","iopub.status.idle":"2025-02-10T14:14:01.427827Z","shell.execute_reply.started":"2025-02-10T14:10:54.807882Z","shell.execute_reply":"2025-02-10T14:14:01.424352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XG_roc_auc_train = roc_auc_score(y_train, predictions_train[:,1])\nfpr_train_XG, tpr_train_XG, thresholds_train_XG = roc_curve(y_train, predictions_train[:,1])\nplt.figure()\nplt.plot(fpr_train_XG, tpr_train_XG, label='XG Boost (area = %0.2f)' % XG_roc_auc_train)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic training data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:14:21.303687Z","iopub.execute_input":"2025-02-10T14:14:21.304089Z","iopub.status.idle":"2025-02-10T14:14:21.648331Z","shell.execute_reply.started":"2025-02-10T14:14:21.304062Z","shell.execute_reply":"2025-02-10T14:14:21.647137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XG_roc_auc_test = roc_auc_score(y_test, predictions_test[:,1])\nfpr_test_XG, tpr_test_XG, thresholds_test_XG = roc_curve(y_test, predictions_test[:,1])\nplt.figure()\nplt.plot(fpr_test_XG, tpr_test_XG, label='XG Boost (area = %0.2f)' % XG_roc_auc_test)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic test data')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:14:25.703036Z","iopub.execute_input":"2025-02-10T14:14:25.70346Z","iopub.status.idle":"2025-02-10T14:14:26.042644Z","shell.execute_reply.started":"2025-02-10T14:14:25.703428Z","shell.execute_reply":"2025-02-10T14:14:26.041232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_x_test=pd.DataFrame(x_test)\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(model, df_x_test, y_test,\n                            n_repeats=30,\n                            random_state=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:17:14.103097Z","iopub.execute_input":"2025-02-10T14:17:14.103668Z","iopub.status.idle":"2025-02-10T14:21:27.379897Z","shell.execute_reply.started":"2025-02-10T14:17:14.103629Z","shell.execute_reply":"2025-02-10T14:21:27.378842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.concat([pd.DataFrame({'Variable': pd.DataFrame(X_def).columns.tolist()}),pd.DataFrame({'Importance':result.importances_mean})],axis=1)\ndf1=df.sort_values(by='Importance',ascending=False)\ndf1.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:21:55.528583Z","iopub.execute_input":"2025-02-10T14:21:55.529035Z","iopub.status.idle":"2025-02-10T14:21:55.54652Z","shell.execute_reply.started":"2025-02-10T14:21:55.529003Z","shell.execute_reply":"2025-02-10T14:21:55.544919Z"}},"outputs":[],"execution_count":null}]}