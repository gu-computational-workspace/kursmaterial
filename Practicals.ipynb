{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4957151-3919-4646-b06a-25b149c2051c",
   "metadata": {},
   "source": [
    "# OC4920 - GEOSTROPHY\n",
    "\n",
    "## Outline\n",
    "\n",
    "Good morning everyone!\n",
    "\n",
    "So yesterday, we talked about geostrophic velocities and two different ways of estimating them. The first from horizontal sea surface height gradients (horizontal along height/depth), the second from horizontal density gradients (horizontal along isobars).\n",
    "\n",
    "The first method provides absolute mean velocities for the entire water column, *ie*. the barotropic component of the geostrophic velocity.\n",
    "\n",
    "The second method provides *no* velocity measurements but provides the vertical structure of the currents, $\\delta u / \\delta z$, also called vertical shear.\n",
    "\n",
    "You will by now have read through Estel's paper and have an understanding of why we may want to measure flows at this location. Persian Gulf Water flows out of the Strait of Hormuz as a gravity current, rapidly adjusting down the slope, and flowing out into the Oxygen Minimum Zone. The current really stands out with a much warmer, more saline and oxygenated signature.\n",
    "\n",
    "One aspect that emerges from the paper is the huge variability in PGW concentration and transport, both intraseasonally and interannually. We finish the paper with a first estimate of transport, but also a clear understanding that we have **not** resolved the variability in the system. To do so, we need more measurements over a longer period of time.\n",
    "\n",
    "From this emerges a simple question: does PGW transport have a surface signature? We know the watermass is not visible at the surface, but is the dominant mode of transport one that aligns with the barotropic velocity? Can we derive a proxy for PGW transport from sea surface heigh anomalies? (Ok, that's more like 3 questions, but you get what I mean...)\n",
    "\n",
    "For the overachievers among you, the full dataset is available here ([10.5281/zenodo.10075774](https://zenodo.org/records/10075774)) - to be clear, I do not expect you to answer the question above, but there's nothing stopping us from starting the process.\n",
    "\n",
    "Work together, brainstorm ideas, share code, use ChatGPT, have fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef870bb-3abb-4c27-b955-d62cf59877c9",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244e36f-312c-44f7-a147-bf8ca2ae603c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35084c15-6877-4b69-92b7-60412189e858",
   "metadata": {},
   "source": [
    "### Practical 1 (Tuesday)\n",
    "So the steps to this process will be:\n",
    "- Obtain sea level anomaly (SLA) data from Copernicus Marine Services along the glider transect. Plot it.\n",
    "- Calculate geostrophic velocities from SLA using the equation in lecture one. Plot it.\n",
    "- As this is a learning exercise, we'll also download geostrophic velocities from CMEMS.\n",
    "- Compare your velocities to the CMEMS velocities. Plot this too.\n",
    "- Now download an amount of SLA data that you think will be representative of longer term variability. Surprise - plot this too!\n",
    "- For assessment: \n",
    "    - describe what differences exist between both datasets (if any), \n",
    "    - what you think the source of these differences is. \n",
    "    - Briefly descripe how variable barotropic flows are across the transect location.\n",
    "    - What assumptions did you make, or shortcuts did you take to calculate these velocities. Are they valid?\n",
    "    > (Transect coordinates are :  24.05째N, 57.5째E, to 24.5째N, 57.8째E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0701b44-cc35-4407-9331-40f419cbfb2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83482b-6d03-481c-a81c-e7e685aa304b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4c6d7-429a-4cf1-9964-87f8ab755cf5",
   "metadata": {},
   "source": [
    "### Practical 2 (Wednesday)\n",
    "\n",
    "Today, we collect the glider data ([link here](https://gunet-my.sharepoint.com/:x:/g/personal/bastien_queste_gu_se/EZvSd5h0dwtGq3m3F2ceFL8BaspXJ23Uix_Ie8mWX7u5kg?e=QhY2Tz)) and calculate geostrophic velocities. For this practical, I am giving you only one glider mission. All datasets are provided in the Zenodo link, but the glider data is ~9GB - somewhat over the top for a practical session.\n",
    "\n",
    "- Take the glider timeseries data, notice how data is irregularly spaced in space and the glider deviates from transect.\n",
    "- Create gridded sections of glider density data - think about how you might project the data onto a straight transect (you may want to brainstorm as a group there).\n",
    "- Think about if any filtering (smoothing) is necessary?\n",
    "- Calculate horizontal distances to get horizontal density gradients (along isobars).\n",
    "- Calculate vertical shear and integrate vertically to get unreferenced geostrophic velocity profiles (code it up by hand, no TEOS-10 shortcuts please - to be honest though, it's not much of a shortcut).\n",
    "- Create referenced geostrophic velocity sections using altimetry data.\n",
    "- For assessment:\n",
    "    - How does it compare to selecting a level of no motion (say at depth, or near the seabed)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd18a0-8832-403d-8a3f-b50da7205afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here's a useful gridding function that is quick and generally painfree\n",
    "def grid2d(x, y, v, xi=1, yi=1, fn='median'):\n",
    "    \"\"\"\n",
    "    Quick data binning function relying on pandas.\n",
    "    x,y,v are flat np.arrays of x, y coordinates and values at these points.\n",
    "    xi and yi are either np.arrays of bins to be binned into, or the spacing used between min and max of x or y respectively.\n",
    "    fn defines the function applied to all points from v that fall into the same bin.\n",
    "    \"\"\"\n",
    "    if np.size(xi) == 1:\n",
    "        xi = np.arange(np.nanmin(x), np.nanmax(x) + xi, xi)\n",
    "    if np.size(yi) == 1:\n",
    "        yi = np.arange(np.nanmin(y), np.nanmax(y) + yi, yi)\n",
    "\n",
    "    raw = pd.DataFrame({'x': x, 'y': y, 'v': v}).dropna()\n",
    "\n",
    "    grid = np.full([np.size(yi), np.size(xi)], np.nan)\n",
    "\n",
    "    raw['xbins'], xbin_iter = pd.cut(raw.x, xi, retbins=True, labels=False, right=False)\n",
    "    raw['ybins'], ybin_iter = pd.cut(raw.y, yi, retbins=True, labels=False, right=False)\n",
    "\n",
    "    _tmp = raw.groupby(['xbins', 'ybins'])['v'].agg(fn)\n",
    "    grid[\n",
    "        _tmp.index.get_level_values(1).astype(int),\n",
    "        _tmp.index.get_level_values(0).astype(int),\n",
    "    ] = _tmp.values\n",
    "\n",
    "    XI, YI = np.meshgrid(xi, yi, indexing='ij')\n",
    "    return grid, XI.T, YI.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6faf5f-dff0-492d-b27b-0f997b9528e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('glider_data_subset.csv', delimiter=',', parse_dates=['time',])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a227c8-ae9d-42ea-9756-55b130137752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7605ceb-0b2f-47c8-af7d-8419d7653089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752c2d5-d296-4472-8a2f-c4e5b7a65f6c",
   "metadata": {},
   "source": [
    "### Practical 3 (Thursday)\n",
    "\n",
    "Practical 3 takes it beyond geostrophic velocities. Today, we use direct measurements of velocity using the ADCP mounted to the glider ([ADCP data file 1](https://gunet-my.sharepoint.com/:u:/g/personal/bastien_queste_gu_se/Ea_le-4JRtZMnNyCJHpwyB0Bx8F2VvCamlLG4kFnBd-uMQ?e=bvgEId) and [ADCP data file 2](https://gunet-my.sharepoint.com/:u:/g/personal/bastien_queste_gu_se/EXOWr8VDhAFIg-x9TXxKCMMBMJWBO9xqn4Ee6GAe8lVbeA?e=DOwvP8)).\n",
    "Install the gliderad2cp toolbox:\n",
    "> pip install --user gliderad2cp\n",
    "\n",
    "- Follow instructions to use the gliderad2cp toolbox using guidance from https://github.com/bastienqueste/gliderad2cp/tree/main and https://www.flow-lab.org/gliderad2cp/.\n",
    "- You will need to provide latitudes and longitudes for the start and end of each dive. The `dead_reckoning` variable indicates if GPS coordinates are from the dead reckoning model (True) or from GPS readings (False). I provide example code below:\n",
    "- Assessment:\n",
    "    - Critically assess the ADCP data.\n",
    "    - How does it compare to the geostrophic velocities?\n",
    "    - Suggest a way of referencing geostrophic velocities using the ADCP data\n",
    "    - Where do ADCP data and geostrophic velocities differ most? What can that tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce439e-7731-4251-95a3-1c30e7c23d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gps_predive = []\n",
    "gps_postdive = []\n",
    "\n",
    "dives = np.round(np.unique(data.dive_num))\n",
    "\n",
    "_idx = np.arange(len(data.dead_reckoning.values))\n",
    "for dn in dives:\n",
    "    _gd = (data.dive_num.values == dn).astype('float')\n",
    "    _gd[_gd < 1] = np.nan\n",
    "    \n",
    "    _dp = (data.pressure.values > 10).astype('float')\n",
    "    _dp[_dp < 1] = np.nan\n",
    "\n",
    "    if all(np.isnan(_gd)):\n",
    "        plt.plot(_dr)\n",
    "        continue\n",
    "\n",
    "    first = int(np.nanmin(_idx * _gd))+20\n",
    "    last  = int(np.nanmin(_idx * _gd * _dp))\n",
    "\n",
    "        \n",
    "    # print(first,last)\n",
    "    gps_postdive.append(np.array([data.time.values[first], data.longitude.values[first], data.latitude.values[first]]))\n",
    "    gps_predive.append(np.array([data.time.values[last], data.longitude.values[last], data.latitude.values[last]]))\n",
    "\n",
    "gps_predive = np.vstack(gps_predive)\n",
    "gps_postdive = np.vstack(gps_postdive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23216fc7-ebed-47d3-bea7-37f8e72ebb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gliderad2cp import process_currents, process_shear, process_bias, tools\n",
    "\n",
    "options = tools.get_options(xaxis=1, yaxis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55383f7-e554-4442-9864-08e032a79ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_adcp = process_shear.process('*.nc', data, options)\n",
    "currents, DAC = process_currents.process(ds_adcp, gps_predive, gps_postdive, options)\n",
    "# currents = process_bias.process(currents,options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48dde7d-3667-443e-a22c-c4ec730a5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07421dcc-618b-4981-8673-2d070a3d6588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
